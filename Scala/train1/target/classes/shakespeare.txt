The above assumes that Discovery Hive Metastore service has already been started. SPARK_HOME configuration is specified to run with Spark v1.6.3. SQL_INCREMENTAL_COLLECT configuration is required to allow spark thrift server to stream results to the client a partition at a time, instead of running collect() and loading the complete result set into memory first. Loading the complete result set into memory first will cause out-of-memory error when building an Intelligent Cube. Both spark thrift server and its spark driver memory has been configured to 16GB. Considering incremental collect option its likely that memory requiremts can be reduced. The final memory size should be drived at with additional experimentation given partition data sizes. With the above configuration the url for connecting to spark thift server froma client is spark-thriftserver-1.discovery.skynet.quantium.com.au:10000 When connecting from beeline the command is !connect jdbc:hive2://spark-thriftserver-1.discovery.skynet.quantium.com.au:10000 NOTE: There are new changes to security in the cluster and you need to be a member of admin group to be able to stop an app that you started with RUN_AS that is not your account. Be careful, because it will let you start it, but won;t let you stop. Ask Platform Team about how to become a member of discovery admin group.